---
title: "ARCWATCH-1: 16S rRNA amplicons"
---

This markdown describes processing of 16S rRNA amplicons, originating from seawater and sea-ice  samples from expedition Arcwatch-1 (central Arctic Ocean, 2023).

First: Primer clipping using *Cutadapt*  

# 1st MiSeq run
```{console}

######################################################################
  ## MiSeq L2MMN ##
######################################################################

cd /isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138

#copy fastq files from netscratch 
cp/isibhv/netscratch/miseq/M03457_0137_000000000-L2MMN//isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138/

# Fetch fastqs from TapeArchive via custom script
# Names listed in files_KV5KT.txt
/isibhv/projects/p_bioinf2/miseq/copy-files-from-tape.sh files_L2MMN.txt

# Rename / remove MiSeq run-ID 
rename 'M03457_0137_000000000-L2MMN' 'L2MMN' *
cd L2MMN
mkdir Original
mv *gz Original

######################################

module load /albedo/soft/modules/bio/cutadapt/4.4

# Use custom script 
bash ../../../software/cutadapt.sh ./Original GTGYCAGCMGCCGCGGTAA CCGYCAATTYMTTTRAGTTT

# One sample = two fastq files
# Create unique names - so not overwritten in following batch-rename 
cd Clipped
find . -type f -name '*-8U-16S-25c_S5_*' -exec sh -c 'mv "$0" "$(echo "$0" | sed "s/-8U-16S-25c_S5_/-8Upoint1-16S-25c_S5_/")"' {} \;
find . -type f -name '*-8U-16S-25c_S85_*' -exec sh -c 'mv "$0" "$(echo "$0" | sed "s/-8U-16S-25c_S85_/-8Upoint2-16S-25c_S85_/")"' {} \;

# Shortening filenames
# First: test-rename
for i in *fastq.gz; do nname=`echo $i | awk '{gsub(/S[0-9]{1,3}_L001/,"clip");print}'`; echo -e $i $nname; done

# if looking OK - execute:  
for i in *fastq.gz; do nname=`echo $i | awk '{gsub(/S[0-9]{1,3}_L001/,"clip");print}'`; mv $i $nname; done

# write sampleNames for dada
ls -1 *R1_001.fastq.gz | sed 's/_R1_001\.fastq.gz//' > ../sampleNames.txt

```

*DADA2 amplicon analysis*

# done in RStudio within AWI-VM
# provided IP address opened in browser
# adjust for your own system 

```{r, eval = F}

require(dada2)
require(ShortRead)
require(ggplot2)
require(gridExtra)

##########################################

# setwd 
setwd("/isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138/")

# list files
path <- "/isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138/L2MMN/Clipped"
fns <- list.files(path)
fns

# ensure fwd/rev reads  in same order
fnFs <- sort(list.files(path, pattern="_R1_001.fastq.gz"))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq.gz"))

# Define sample names
sampleNames <- sort(read.table(
  "sampleNames.txt", 
  h=F, stringsAsFactors=F)$V1)

# Specify the full path to the fnFs and fnRs
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)

#################################

# Quality check
QualityProfileFs <- list()
for(i in 1:length(fnFs)) {QualityProfileFs[[i]] <- list()
  QualityProfileFs[[i]][[1]] <- plotQualityProfile(fnFs[i])}
pdf("QualityProfileForward.pdf")
for(i in 1:length(fnFs)) {do.call("grid.arrange", 
    QualityProfileFs[[i]])}
dev.off()
rm(QualityProfileFs)

QualityProfileRs <- list()
for(i in 1:length(fnRs)) {
  QualityProfileRs[[i]] <- list()
  QualityProfileRs[[i]][[1]] <- plotQualityProfile(
    fnRs[i])}
pdf("QualityProfileReverse.pdf")
for(i in 1:length(fnRs)) {do.call("grid.arrange", 
  QualityProfileRs[[i]])}
dev.off()
rm(QualityProfileRs)
# rev-reads as expected with lower qual, but OK
# 10microm−15plus16U failed
# 10microm−6Upoint1 suboptimal
# overall strange: blanks with many reads... 

# Prepare for fastq filtering
filt_path <- file.path(path, "../Filtered")
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(
  filt_path, paste0(sampleNames, "_F_filt.fastq"))
filtRs <- file.path(
  filt_path, paste0(sampleNames, "_R_filt.fastq"))

#################################

## Filter 
# Consider expected overlap
# truncLen lowered based on QualityProfile (low-Q rev-reads)
out <- filterAndTrim(
  fnFs, 
  filtFs, 
  fnRs, 
  filtRs,
  truncLen = c(240, 195),
  maxN = 0,
  minQ = 2,
  maxEE = c(3, 3), 
  truncQ = 0, 
  rm.phix = T,
  compress=F,
  multithread = T)

# Should retain >70% -- 0.7 here -- OK
head(out)
summary(out[, 2]/out[, 1])

#################################

# Quality check 
QualityProfileFs.filt <- list()
for(i in 1:length(filtFs)) {
  QualityProfileFs.filt[[i]] <- list()
  QualityProfileFs.filt[[i]][[1]] <- plotQualityProfile(
    filtFs[i])}
pdf("QualityProfileForwardFiltered.pdf")
for(i in 1:length(filtFs)) {do.call("grid.arrange", 
    QualityProfileFs.filt[[i]])}
dev.off()
rm(QualityProfileFs.filt)

QualityProfileRs.filt <- list()
for(i in 1:length(filtRs)) {
  QualityProfileRs.filt[[i]] <- list()
  QualityProfileRs.filt[[i]][[1]] <- plotQualityProfile(
    filtRs[i])}
pdf("QualityProfileReverseFiltered.pdf")
for(i in 1:length(filtRs)) {  do.call("grid.arrange", 
    QualityProfileRs.filt[[i]])}
dev.off()
rm(QualityProfileRs.filt)

#################################

# Learn errors 
errF <- learnErrors(
  filtFs, multithread=24, 
  randomize=T, verbose=1, MAX_CONSIST=20)
errR <- learnErrors(
  filtRs, multithread=24, 
  randomize=T, verbose=1, MAX_CONSIST=20)

# Plot error profiles
pdf("ErrorProfiles.pdf")
plotErrors(errF, nominalQ = T)
plotErrors(errR, nominalQ = T)
dev.off()
# convergence after 5-5 rounds - ok!
# few outliers outside black line - ok!

# Dereplication 
derepFs <- derepFastq(filtFs, verbose=T)
derepRs <- derepFastq(filtRs, verbose=T)

# Rename by clip-filenames
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames

# Denoising
dadaFs <- dada(
  derepFs, err=errF, multithread=24, pool=T)
dadaRs <- dada(
  derepRs, err=errR, multithread=24, pool=T)

#################################

# Read merging
mergers <- mergePairs(
  dadaFs, 
  derepFs, 
  dadaRs,
  derepRs,
  minOverlap=15,
  verbose=T,
  propagateCol = c(
    "birth_fold", 
    "birth_ham"))

# Create sequence table
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 15877 sequences
saveRDS(seqtab, 
  "seqtab_16S_traps.rds")

# summary stats
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(
  dadaFs, getN), sapply(mergers, getN), 
  rowSums(seqtab))
colnames(track) <- c(
  "input","filtered","denoised",
  "merged","tabled")
rownames(track) <- sampleNames
track <- data.frame(track)
head(track)

write.table(track, 
  "dadastats_16S_traps.txt", 
  quote=F, sep="\t")

save.image("16S_Traps.Rdata")

```
#2nd Miseq run

```{console}

######################################################################
  ## MiSeq run L9424 ##
######################################################################

# change to working directory
cd /isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138/
  
#copy fastq files from netscratch 
cp /isibhv/netscratch/fqs_240105_M03457_0140_000000000-L9424/ /isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138/


  
# Fetch fastqs from TapeArchive via custom script
# Fastq listed in files_KMBTT.txt
/isibhv/projects/p_bioinf2/miseq/copy-files-from-tape.sh files_L9424.txt

# Rename / remove MiSeq run-ID 
rename 'M03457_0140_000000000-L9424' 'L9424' *
cd L9424
mkdir Original
mv *gz Original

######################################

module load /albedo/soft/modules/bio/cutadapt/4.4

# Use custom script 
bash ../../../software/cutadapt.sh ./Original GTGYCAGCMGCCGCGGTAA CCGYCAATTYMTTTRAGTTT

# Shortenening filenames
# First: test-rename
cd Clipped
for i in *fastq.gz; do nname=`echo $i | awk '{gsub(/S[0-9]{1,3}_L001/,"clip");print}'`; echo -e $i $nname; done

# if looking OK - execute:  
for i in *fastq.gz; do nname=`echo $i | awk '{gsub(/S[0-9]{1,3}_L001/,"clip");print}'`; mv $i $nname; done

# write sampleNames for dada
ls -1 *R1_001.fastq.gz | sed 's/_R1_001\.fastq.gz//' > ../sampleNames.txt

```

*DADA2 amplicon analysis*

# done in RStudio within AWI-VM
# provided IP address opened in browser
# adjust for your own system 

```{r, eval = F}

require(dada2)
require(ShortRead)
require(ggplot2)
require(gridExtra)

##########################################

# setwd 
setwd("/isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138/L9424/")

# list files
path <- "/isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138/L9424//Clipped"
fns <- list.files(path)
fns

# ensure fwd/rev reads  in same order
fnFs <- sort(list.files(path, pattern="_R1_001.fastq.gz"))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq.gz"))

# Define sample names
sampleNames <- sort(read.table(
  "sampleNames.txt", 
  h=F, stringsAsFactors=F)$V1)

# Specify the full path to the fnFs and fnRs
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)

#################################

# Quality check
QualityProfileFs <- list()
for(i in 1:length(fnFs)) {QualityProfileFs[[i]] <- list()
  QualityProfileFs[[i]][[1]] <- plotQualityProfile(fnFs[i])}
pdf("QualityProfileForward.pdf")
for(i in 1:length(fnFs)) {do.call("grid.arrange", 
    QualityProfileFs[[i]])}
dev.off()
rm(QualityProfileFs)

QualityProfileRs <- list()
for(i in 1:length(fnRs)) {
  QualityProfileRs[[i]] <- list()
  QualityProfileRs[[i]][[1]] <- plotQualityProfile(
    fnRs[i])}
pdf("QualityProfileReverse.pdf")
for(i in 1:length(fnRs)) {do.call("grid.arrange", 
  QualityProfileRs[[i]])}
dev.off()
rm(QualityProfileRs)
# rev-reads as expected with lower qual, but OK

# Prepare for fastq filtering
filt_path <- file.path(path, "../Filtered")
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(
  filt_path, paste0(sampleNames, "_F_filt.fastq"))
filtRs <- file.path(
  filt_path, paste0(sampleNames, "_R_filt.fastq"))

#################################

## Filter 
# Consider expected overlap
# truncLen lowered based on QualityProfile (low-Q rev-reads)
out <- filterAndTrim(
  fnFs, 
  filtFs, 
  fnRs, 
  filtRs,
  truncLen = c(240, 195),
  maxN = 0,
  minQ = 2,
  maxEE = c(3, 3), 
  truncQ = 0, 
  rm.phix = T,
  compress=F,
  multithread = 12)

# Should retain >70% -- 0.8 here -- OK
head(out)
summary(out[, 2]/out[, 1])

#################################

# Quality check 
QualityProfileFs.filt <- list()
for(i in 1:length(filtFs)) {
  QualityProfileFs.filt[[i]] <- list()
  QualityProfileFs.filt[[i]][[1]] <- plotQualityProfile(
    filtFs[i])}
pdf("QualityProfileForwardFiltered.pdf")
for(i in 1:length(filtFs)) {do.call("grid.arrange", 
    QualityProfileFs.filt[[i]])}
dev.off()
rm(QualityProfileFs.filt)

QualityProfileRs.filt <- list()
for(i in 1:length(filtRs)) {
  QualityProfileRs.filt[[i]] <- list()
  QualityProfileRs.filt[[i]][[1]] <- plotQualityProfile(
    filtRs[i])}
pdf("QualityProfileReverseFiltered.pdf")
for(i in 1:length(filtRs)) {  do.call("grid.arrange", 
    QualityProfileRs.filt[[i]])}
dev.off()
rm(QualityProfileRs.filt)

#################################

# Learn errors 
errF <- learnErrors(
  filtFs, multithread=24, 
  randomize=T, verbose=1, MAX_CONSIST=20)
errR <- learnErrors(
  filtRs, multithread=24, 
  randomize=T, verbose=1, MAX_CONSIST=20)

# Plot error profiles
pdf("ErrorProfiles.pdf")
plotErrors(errF, nominalQ = T)
plotErrors(errR, nominalQ = T)
dev.off()
# convergence after 6-5 rounds - ok!
# few outliers outside black line - ok!

# Dereplication 
derepFs <- derepFastq(filtFs, verbose=T)
derepRs <- derepFastq(filtRs, verbose=T)

# Rename by clip-filenames
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames

# Denoising
dadaFs <- dada(
  derepFs, err=errF, multithread=24, pool=T)
dadaRs <- dada(
  derepRs, err=errR, multithread=24, pool=T)

#################################

# Read merging
mergers <- mergePairs(
  dadaFs, 
  derepFs, 
  dadaRs,
  derepRs,
  minOverlap=15,
  verbose=T,
  propagateCol = c(
    "birth_fold", 
    "birth_ham"))

# Create sequence table
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 2762 sequences
saveRDS(seqtab, 
  "seqtab_16S_ras.rds")

# summary stats
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(
  dadaFs, getN), sapply(mergers, getN), 
  rowSums(seqtab))
colnames(track) <- c(
  "input","filtered","denoised",
  "merged","tabled")
rownames(track) <- sampleNames
track <- data.frame(track)
head(track)

write.table(track, 
  "dadastats_16S_ras.txt", 
  quote=F, sep="\t")

save.image("16S_RAS.Rdata")

```

Next we analyze the 3rd MiSeq run.

```{console}

######################################################################
  ## MiSeq L2MMN ##
######################################################################

cd /isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138

#copy fastq files from netscratch 
cp/isibhv/netscratch/miseq/M03457_0137_000000000-L2MMN//isibhv/projects/FRAMdata/MolObs/WaterCol_CTD_PS138/

# Fetch fastqs from TapeArchive via custom script
# Names listed in files_KV5KT.txt
/isibhv/projects/p_bioinf2/miseq/copy-files-from-tape.sh files_KV5KT.txt

# Rename / remove MiSeq run-ID 
rename 'M03457_0137_000000000-L2MMN' 'L2MMN' *
cd L2MMN
mkdir Original
mv *gz Original

######################################

module load /albedo/soft/modules/bio/cutadapt/4.4

# Use custom script 
bash ../../../software/cutadapt.sh ./Original GTGYCAGCMGCCGCGGTAA CCGYCAATTYMTTTRAGTTT

# One sample = two fastq files
# Create unique names - so not overwritten in following batch-rename 
cd Clipped
find . -type f -name '*-8U-16S-25c_S5_*' -exec sh -c 'mv "$0" "$(echo "$0" | sed "s/-8U-16S-25c_S5_/-8Upoint1-16S-25c_S5_/")"' {} \;
find . -type f -name '*-8U-16S-25c_S85_*' -exec sh -c 'mv "$0" "$(echo "$0" | sed "s/-8U-16S-25c_S85_/-8Upoint2-16S-25c_S85_/")"' {} \;

# Shortening filenames
# First: test-rename
for i in *fastq.gz; do nname=`echo $i | awk '{gsub(/S[0-9]{1,3}_L001/,"clip");print}'`; echo -e $i $nname; done

# if looking OK - execute:  
for i in *fastq.gz; do nname=`echo $i | awk '{gsub(/S[0-9]{1,3}_L001/,"clip");print}'`; mv $i $nname; done

# write sampleNames for dada
ls -1 *R1_001.fastq.gz | sed 's/_R1_001\.fastq.gz//' > ../sampleNames.txt

```

*DADA2 amplicon analysis*

# done in RStudio within AWI-VM
# provided IP address opened in browser
# adjust for your own system 

```{r, eval = F}

require(dada2)
require(ShortRead)
require(ggplot2)
require(gridExtra)

##########################################

# setwd 
setwd("/isibhv/projects/FRAMdata/MolObs/WeddellSea_BGC1/bacteria/KV5KT/")

# list files
path <- "/isibhv/projects/FRAMdata/MolObs/WeddellSea_BGC1/bacteria/KV5KT/Clipped"
fns <- list.files(path)
fns

# ensure fwd/rev reads  in same order
fnFs <- sort(list.files(path, pattern="_R1_001.fastq.gz"))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq.gz"))

# Define sample names
sampleNames <- sort(read.table(
  "sampleNames.txt", 
  h=F, stringsAsFactors=F)$V1)

# Specify the full path to the fnFs and fnRs
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)

#################################

# Quality check
QualityProfileFs <- list()
for(i in 1:length(fnFs)) {QualityProfileFs[[i]] <- list()
  QualityProfileFs[[i]][[1]] <- plotQualityProfile(fnFs[i])}
pdf("QualityProfileForward.pdf")
for(i in 1:length(fnFs)) {do.call("grid.arrange", 
    QualityProfileFs[[i]])}
dev.off()
rm(QualityProfileFs)

QualityProfileRs <- list()
for(i in 1:length(fnRs)) {
  QualityProfileRs[[i]] <- list()
  QualityProfileRs[[i]][[1]] <- plotQualityProfile(
    fnRs[i])}
pdf("QualityProfileReverse.pdf")
for(i in 1:length(fnRs)) {do.call("grid.arrange", 
  QualityProfileRs[[i]])}
dev.off()
rm(QualityProfileRs)
# rev-reads as expected with lower qual, but OK
# 10microm−15plus16U failed
# 10microm−6Upoint1 suboptimal
# overall strange: blanks with many reads... 

# Prepare for fastq filtering
filt_path <- file.path(path, "../Filtered")
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(
  filt_path, paste0(sampleNames, "_F_filt.fastq"))
filtRs <- file.path(
  filt_path, paste0(sampleNames, "_R_filt.fastq"))

#################################

## Filter 
# Consider expected overlap
# truncLen lowered based on QualityProfile (low-Q rev-reads)
out <- filterAndTrim(
  fnFs, 
  filtFs, 
  fnRs, 
  filtRs,
  truncLen = c(240, 195),
  maxN = 0,
  minQ = 2,
  maxEE = c(3, 3), 
  truncQ = 0, 
  rm.phix = T,
  compress=F,
  multithread = T)

# Should retain >70% -- 0.7 here -- OK
head(out)
summary(out[, 2]/out[, 1])

#################################

# Quality check 
QualityProfileFs.filt <- list()
for(i in 1:length(filtFs)) {
  QualityProfileFs.filt[[i]] <- list()
  QualityProfileFs.filt[[i]][[1]] <- plotQualityProfile(
    filtFs[i])}
pdf("QualityProfileForwardFiltered.pdf")
for(i in 1:length(filtFs)) {do.call("grid.arrange", 
    QualityProfileFs.filt[[i]])}
dev.off()
rm(QualityProfileFs.filt)

QualityProfileRs.filt <- list()
for(i in 1:length(filtRs)) {
  QualityProfileRs.filt[[i]] <- list()
  QualityProfileRs.filt[[i]][[1]] <- plotQualityProfile(
    filtRs[i])}
pdf("QualityProfileReverseFiltered.pdf")
for(i in 1:length(filtRs)) {  do.call("grid.arrange", 
    QualityProfileRs.filt[[i]])}
dev.off()
rm(QualityProfileRs.filt)

#################################

# Learn errors 
errF <- learnErrors(
  filtFs, multithread=24, 
  randomize=T, verbose=1, MAX_CONSIST=20)
errR <- learnErrors(
  filtRs, multithread=24, 
  randomize=T, verbose=1, MAX_CONSIST=20)

# Plot error profiles
pdf("ErrorProfiles.pdf")
plotErrors(errF, nominalQ = T)
plotErrors(errR, nominalQ = T)
dev.off()
# convergence after 5-5 rounds - ok!
# few outliers outside black line - ok!

# Dereplication 
derepFs <- derepFastq(filtFs, verbose=T)
derepRs <- derepFastq(filtRs, verbose=T)

# Rename by clip-filenames
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames

# Denoising
dadaFs <- dada(
  derepFs, err=errF, multithread=24, pool=T)
dadaRs <- dada(
  derepRs, err=errR, multithread=24, pool=T)

#################################

# Read merging
mergers <- mergePairs(
  dadaFs, 
  derepFs, 
  dadaRs,
  derepRs,
  minOverlap=15,
  verbose=T,
  propagateCol = c(
    "birth_fold", 
    "birth_ham"))

# Create sequence table
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 15877 sequences
saveRDS(seqtab, 
  "seqtab_16S_traps.rds")

# summary stats
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(
  dadaFs, getN), sapply(mergers, getN), 
  rowSums(seqtab))
colnames(track) <- c(
  "input","filtered","denoised",
  "merged","tabled")
rownames(track) <- sampleNames
track <- data.frame(track)
head(track)

write.table(track, 
  "dadastats_16S_traps.txt", 
  quote=F, sep="\t")

save.image("16S_Traps.Rdata")

```
Finally, we merge sequence tables from each run, remove chimeras, and assign taxonomy.

```{r, eval = F}

######################################################################
  ## MERGE, CHIMERAS, TAXONOMY 
######################################################################

setwd("/isibhv/projects/FRAMdata/MolObs/WeddellSea_BGC1/bacteria")

# Load seqtabs
sq1 <- readRDS(
  "./KMBTT/seqtab_16S_ras.rds")
sq2 <- readRDS(
  "./KV5KT/seqtab_16S_traps.rds")

# Merge
seqtab <- mergeSequenceTables(
  sq1, sq2, repeats="error")

# Remove chimeras 
# 13111 bimeras of 18007 sequences.
seqtab.nochim <- removeBimeraDenovo(
  seqtab, method = "consensus", 
  multithread=24, verbose=T)

# 116 samples -- 4992 sequences 
# >95% kept - good!
dim(seqtab.nochim)  
summary(rowSums(seqtab.nochim)/rowSums(seqtab))

# Determine amplicon length/size range 
table(rep(nchar(
  colnames(seqtab.nochim)), 
  colSums(seqtab.nochim)))

# Remove singletons and junk sequences
# "c" adjusted to size range of amplicons
seqtab.nochim2 <- seqtab.nochim[, nchar(
  colnames(seqtab.nochim)) %in% c(362:418) & 
    colSums(seqtab.nochim) > 1]

# Stats
dim(seqtab.nochim2) # 4427 sequences
summary(rowSums(seqtab.nochim2))
summary(rowSums(seqtab.nochim2)/rowSums(seqtab.nochim))

##########################################################

## TAXONOMY -- Silva v138.1 ##

tax <- assignTaxonomy(
  seqtab.nochim2, 
  "../../tax_db/silva_nr99_v138.1_wSpecies_train_set.fa.gz", 
  tryRC = TRUE,
  multithread = 24)

# Archaea 93 -- Bacteria 4327 -- Eukaryota 6
table(tax[, 1])   

# Remove NA on phylum level
sum(is.na(tax[, 2])) #25
tax.good <- tax[!is.na(tax[, 2]),]
seqtab.nochim2.good <- seqtab.nochim2[
  , rownames(tax.good)]
summary(rowSums(seqtab.nochim2.good))

# Format tables
seqtab.nochim2.print <- t(seqtab.nochim2.good)
tax.print <- tax.good
all.equal(rownames(
  seqtab.nochim2.print), 
  rownames(tax.print)) #TRUE
rownames(seqtab.nochim2.print) <- paste(
  "asv", 1:ncol(seqtab.nochim2.good), sep = "")
rownames(tax.print) <- rownames(seqtab.nochim2.print)

# Export
write.table(
  seqtab.nochim2.print,"16S_seqtab.txt", 
  sep="\t", quote=F)
write.table(
  tax.print,"16S_tax.txt", 
  sep="\t", quote=F)
uniquesToFasta(
  seqtab.nochim2.good,
  "16S_uniques.fasta")

#################################

save.image("16S_tax.Rdata")

```
